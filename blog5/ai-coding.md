**Disclaimer**: I hate the term "Vibe Coding", but it seems to have become a synonym for coding fast and loose using AI tools. However, I do like the idea of rapid prototyping, so anything that can help with that sounds like a good idea to me.

**Another Disclaimer**: I wrote the whole article myself with none of the text generated by an LLM so any mistakes are entirely my fault. Some of the images may well be AI generated though - see if you can guess which.

# Bottom Line Up Front

The story so far...

- Benefits
- Problems
- Job replacement or enhancement?
- What do I think about it?

... its ongoing.

# First Steps

## Early Success and Disillusionment

My first foray into AI coding tools was over a year ago using GitHub Copilot in my IDE to make code suggestions, which I could accept and then edit to be more like what I wanted. At first this seemed quite good and it saved me a lot of typing, but the quality of suggestions wasn't particularly high and I spent too much time re-editing the code to make it work. I was already aware of the need to read all the suggested code anyway, which was fine as it saved me a lot of typing (it's easier to type a short natural language prompt than to write the equivalent amount of code). Back then I was less experienced about how to make the best use of prompts to get the results I wanted, which I'm much better at now.

As time went on I found it less and less useful and eventually stopped using it altogether. That was six months ago and things have moved on significantly since then so I decided to investigate Cursor AI to see what that is capable of right now.

## Cutting Through the Hype

When you start looking online for information about AI tools there is a huge amount of content promising instant wealth just by writing a few small webapps with AI coding tools. There is far less information about using it in real world projects in large organisations and applying it to existing code, although I do see occasional articles on LinkedIn every now and then, and I expect the frequency of use will increase. Recently I saw a job advert specifically asking for experience in AI coding tools, so I suspect this will become the norm over time.

Given the confusing number of tools out there and the conflicting opinions about which one is the best, I decided just to go with Cursor AI since it seems to be one of the most established tools available, but obviously there are others. My assumption is that they will all work in pretty much the same way and use the same underlying set of Large Language Models, so the results might not be that different betweem them. I may be wrong of course, but I don't have the bandwidth to try them all.

# Getting Started

Given that I've already dabbled with GitHub Copilot it didn't seem worth trying to use Cursor on an existing project, so it seems best to develop something rapidly from scratch. Actually I worked on two projects: one is a tool aimed at information requirements management, and the other is a productivity tool. The information management application would be too large and be too niche a product to develop under my own funding, so that one is parked for now, but it was a good introduction to Cursor and how to make it do my bidding. The productivity tool should be suitable for a wider audience and is small enough to fund development myself while being large enough to test the AI tools effectively. 

# The Tech Stack

Ideally the tech stack should be something I'm familar with but not so familiar that I'd rather just code it all myself, so I settled on the following:

- Nuxt for the web framework
- Tailwind for the UI components
- TypeScipt for the code
- Docker for containerisation
- Prisma and SQLite for a development database, targeting PostgreSQL for production
- Linux for the development machine

The aim is to get Cursor AI to do as much of the coding as possible because that will be the best way to find its limitations. 

# Coding with Cursor

Before running Cursor, I did use the nuxt command line to initialise a "hello world" project just to get off the ground, then I ran the server in development mode and opened the project directory in the IDE.

## How is the Experience?

It took me a while to work out the level of ganularity of what to ask for in the AI Agent dialog box and initially I was micromanaging it, telling it every little change I wanted, but I quickly learned to ask for things in higher level terms so that it could make wider ranging changes to the code. It is possible to generate a well designed static web site with a single prompt, which appears in your browser like magic, but then you need to get down to the detail of adding more functional features including the basic login/logout, user registration, and storing things in a database, etc.. 

Sometimes adding features was a breeze, other times it took quite a few prompt revisions and retries to get the result I wanted, but also occasionally there were complete Death Spirals where nomatter how I changed the prompts the tool was simply tying itself in kots writing and rewriting code and making the same mistakes over and over again. I can sympathise because I've been there myself sometimes over the years! The only solution to a Death Spiral is to rollback the changes and start again, which is also something I've had to do myself from time to time. So far I'e managed to get what I want in the end with minimal tweaks, but it is useful to follow the same process for each change you want to make, and that is the subject of the next section.

## What process to follow

Like humans, LLMs make mistakes and some LLMs are better than others at writing code, so with that in mind we can develop a process that reduces the chances of mistakes making it into production in much the same way as in a normal development project:

### Pick Your Team

Think of yourself now as being in a pair programming team, you and the AI, so you'll need to pick your partner from the supported model options. You can choose auto LLM selection to get the fastest responses, but this is the equivalent of your pair programming partner being replace with someone else mid feature and you won't get the same results from one feature to the next. I do wonder whether this is the cause of some of the Death Spirals I've encountered. Having tried a few different models I eventually settled on 'claude-3.7-sonnet' as the best one for me because the others don't seem to work as well, but this model can get overloaded by other users so sometimes I drop down to 'claude-3.5-sonnet' and take my chances.

I find it helps to think of the LLM as a fairly experience programmer who can type very fast but who sometimes cuts corners, misunderstands what you mean, or simply forgets what it's doing part way through a task. Don't be too hard on the LLM, it's only human.

### Pick a Feature

It is possible to give the agent a one-line description of a feature and just let it rip, but then you're taking pot luck that the agent can guess what you really want - sometimes it works and sometimes it doesn't. 

I've found the best way is to write a paragraph describing the feature and how it should behave, ideally in a separate area. One option that worked well was to write GitHub issues with the feature description, and ask the agent simply to "use gh to read issue X and implement". If you try to write the description directly in the agent text box it's too tempting to hit the enter button too soon before you have a proper description of the feature.

Once you have the feature description tied down you can move on to the next step, but first make sure there are no outstanding changes to commit and be sure to start with a new agent conversation.

### Prompt the Agent

Now the fun begins, especially if you're working with something that supports hot reloading. Enter the prompt and sit back and watch the magic happen. You may see the agent backtrack and re-implement something, but you should see the changes take effect and see changed files appearing in the Git tab (sometimes you have to refresh it manually) until it completes the task you gave it - if it's still working you'll see the "Generating..." text in the agent. With luck you'll now have a fully implemented feature, but you may have to iterate to get it complete.

### Review the Changes

The next place to look is the Git tab where you should read through all the changes made to make sure they're sensible. If you're impatient like me sometimes you will skip this in your excitement to see it working, but you really must do this before commiting anything to Git!

### Test the Results

If you have hot reloading then great, test the new feature, but if it doesn't work you'll need to ask the agent to make addition changes. If there are errors you can copy the error to the agent and say "fix this", because it's quite good at working out what went wrong.

I also recommend testing any functionality related to the files changed, because it can break existing features just like a human can.

### Accept the Changes

Usually the agent will ask you to accept or reject the changes from the recent prompts, so accept them if they look good or reject and try again if not. This doesn't commit the changes to Git so you'll do that next.

### Commit the Changes

Since you didn't review the changes when I told you to you'll really have to do that now. Just because the feature works doesn't mean the code is correct. If you're happy then go ahead and commit - you can get the AI to generate the commit text as well if you prefer. You can just rollback the changes if they're not up to scratch and try again with a clean agent conversation.

### Start a Clean Prompt

It seems like a good idea to start with a clean prompt at least for eacxh ferature, and maybe more often than that, because the context window can get cluttered with irrelevant junk that confuses the LLM and may take you into a Death Spiral.

## What are the benefits

Like most things in life AI coding tools aren't perfect, but they are useful, so here is a breakdown of some of the benefits I've found:

1. Speed - it can generate a lot of code for a relatively small prompt. This can make you a lot more productive, especially for the simpler tasks, which leaves more time to fix problems or work on the more difficult features.
1. Speed - again? Yes. You can iterate faster which reduces the cost of just trying something out and then abandoning it. If you don't really know how you want a feature to work you can create something simple and iterate from there. Possibly even roll it back completely and start again relatively quickly.
1. Speed! - I've been able to produce two non-trivial prototypes in the space of 6 working days, one of which is suitable as an MVP for public beta testing - more on that in another blog post.
1. Higher Level Focus - you can think more about the features rather than about the detail of a piece of code, so you can think more strategically about your application.
1. Learning - if you can code in one language you can usually read others fairly easily and make manual changes even though you're not an expert. Seeing how the LLM implements features, uses the language, and uses the frameworks, will mean you learn about them too as you go.
1. Quality of Life - as a developer I can sometimes feel bogged down in the weeds of the code, but with the AI tools I feel more productive and more business focussed (at least as long as I'm not in one of the Death Spirals).
1. Cost - your pair programming partner is cheaper than hiring someone else.

## What are the problems

Now for the problems, which aren't trivial and shouldn't be ovelooked if we're still cutting through the hype:

1. Cost - yes we had this before, but each AI request uses up credit that is included in your subscription so you may have to upgrade your plan or pay for additional usage at some point. There's no such thing as a free lunch.
1. Death Spirals - it was tempting to list this first! They're frustrating but you canget out of them quicker than you can compared to one of your own Death Spirals because you've put less effort into them and are less invested in them. Once you recognise the Death Spiral, climb out.
1. Quality - this might be a killer for some types of project. I can't vouch for the production quality of the code, but I have seem code duplication, poor code choices, and other problems that you could pick up in reviews and will have to change manually. If you follow a decent development process you will find any issues, but then you will need to ask yourself whether you're really saving very much by using AI.
1. Limited Credits - My subscription has 500 fast credits per month, which means that once they're used up I will have unlimited slow credits for the rest of the month. Slow credits are for smaller, slower LLMs so I expect my productivity will nosedive when that happens. I'm getting close to that so I'll cover it in the next blog.

## How has it changed me

It's early days but I have definitely noticed a change in my approach to development. Most of my career I've been interested more in the code than the application. I love the control I have and there is joy in writing clean, high quality code the solves a real world problem. Having said that I'm sure that a lot of my code wasn't as robust as it could have been though.

This exercise is changing the way I look at software development now, and I find myself more concerned with the business aspects of the application rather than the detail of the code. This transformation has only taken a couple of weeks, and I'm not sure whether its the AI tools that are the cause or merely the fact that I'm trusting the coding to "someone else". 

## Cautions
### check security
### check efficiency
### Don't checkin any files containing passwords or API keys
### Needs experienced developers

# What is coming?

# Progress and the next Blog Post
